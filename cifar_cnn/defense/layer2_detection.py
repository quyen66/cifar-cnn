"""
Layer 2: Distance + Direction Detection (V2 - main.pdf)
=========================================================
PhÃ¢n tÃ­ch sÃ¢u vÃ  "cá»©u vÃ£n" clients tá»« Layer 1.

VAI TRÃ’ LAYER 2:
- Nháº­n káº¿t quáº£ tá»« Layer 1 (REJECTED/FLAGGED/ACCEPTED)
- REJECTED tá»« Layer 1 â†’ Giá»¯ nguyÃªn, KHÃ”NG xá»­ lÃ½
- FLAGGED/ACCEPTED â†’ PhÃ¢n tÃ­ch thÃªm báº±ng Distance + Direction

KIá»‚M TRA (TÆ°Æ¡ng thÃ­ch Full Model & Last Layer):
1. Euclidean Distance: di = ||gi - gref||
   - Vi pháº¡m náº¿u: di > 1.5 Ã— Median({dj})
   - Vá»›i Full Model: di sáº½ lá»›n hÆ¡n nhÆ°ng ngÆ°á»¡ng cÅ©ng tÄƒng theo tá»· lá»‡, logic váº«n Ä‘Ãºng.
   
2. Cosine Similarity: Simi = cos(gi, gref)
   - Vi pháº¡m náº¿u: Simi â‰¤ 0.3 (hÆ°á»›ng ngÆ°á»£c/vuÃ´ng gÃ³c)
   - Vá»›i Full Model: Cosine ráº¥t hiá»‡u quáº£ Ä‘á»ƒ phÃ¡t hiá»‡n Sign Flip/Label Flip.

MA TRáº¬N QUYáº¾T Äá»ŠNH (Giai Ä‘oáº¡n 3 trong PDF):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer1      â”‚ Cosine       â”‚ Euclidean   â”‚ Káº¿t quáº£ Layer 2      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ REJECTED    â”‚ -            â”‚ -           â”‚ REJECTED             â”‚
â”‚ FLAGGED     â”‚ â‰¤ 0.3        â”‚ -           â”‚ REJECTED             â”‚
â”‚ FLAGGED     â”‚ > 0.3        â”‚ fail        â”‚ ACCEPTED (suspicious)â”‚
â”‚ FLAGGED     â”‚ > 0.3        â”‚ pass        â”‚ ACCEPTED (suspicious)â”‚ â† Váº«n nghi ngá» vÃ¬ L1 Ä‘Ã£ flag
â”‚ ACCEPTED    â”‚ â‰¤ 0.3        â”‚ -           â”‚ REJECTED             â”‚
â”‚ ACCEPTED    â”‚ > 0.3        â”‚ fail        â”‚ ACCEPTED (suspicious)â”‚
â”‚ ACCEPTED    â”‚ > 0.3        â”‚ pass        â”‚ ACCEPTED (clean)     â”‚ â† Chá»‰ case nÃ y má»›i clean
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import numpy as np
from typing import List, Dict, Tuple, Optional
from enum import Enum


class Layer2Result(Enum):
    """Káº¿t quáº£ cuá»‘i cÃ¹ng sau Layer 2."""
    REJECTED = "REJECTED"
    ACCEPTED = "ACCEPTED"


class SuspicionLevel(Enum):
    """Má»©c Ä‘á»™ nghi ngá» (chá»‰ Ã¡p dá»¥ng cho ACCEPTED clients)."""
    CLEAN = "clean"           # HoÃ n toÃ n sáº¡ch (L1 ACCEPTED + L2 pass all)
    SUSPICIOUS = "suspicious"  # Cháº¥p nháº­n nhÆ°ng nghi ngá» (dÃ¹ng Ä‘á»ƒ tÃ­nh ci)


class Layer2Detector:
    """
    Layer 2 Detector vá»›i ma tráº­n cá»©u vÃ£n (V2 - main.pdf).
    Há»— trá»£ tham chiáº¿u ngoÃ i (External Reference / Historical Momentum).
    """
    
    def __init__(
        self,
        distance_multiplier: float = 1.5,
        cosine_threshold: float = 0.3,
        enable_rescue: bool = False
    ):
        """
        Initialize Layer 2 Detector.
        """
        self.distance_multiplier = distance_multiplier
        self.cosine_threshold = cosine_threshold
        self.enable_rescue = enable_rescue
        self.last_stats = {}
        
        print(f"âœ… Layer2Detector V2 initialized:")
        print(f"   Distance multiplier: {distance_multiplier}")
        print(f"   Cosine threshold: {cosine_threshold}")

    def detect(
        self,
        gradients: List[np.ndarray],
        client_ids: List[int],
        layer1_results: Dict[int, str],
        current_round: int = 0,
        is_malicious_ground_truth: Optional[List[bool]] = None,
        external_reference: Optional[np.ndarray] = None  # <--- QUAN TRá»ŒNG: Nháº­n Lá»‹ch sá»­ tá»« Server
    ) -> Tuple[Dict[int, str], Dict[int, Optional[str]]]:
        """
        PhÃ¢n tÃ­ch Layer 2 dá»±a trÃªn káº¿t quáº£ Layer 1.
        
        Args:
            gradients: List gradient arrays (Full Model hoáº·c Last Layer)
            client_ids: List client IDs
            layer1_results: Dict[client_id, status] tá»« Layer 1
            current_round: Round hiá»‡n táº¡i
            is_malicious_ground_truth: Ground truth (optional)
            external_reference: Vector tham chiáº¿u tá»« Server (Momentum)
            
        Returns:
            final_status: Dict[client_id, "REJECTED"/"ACCEPTED"]
            suspicion_levels: Dict[client_id, "clean"/"suspicious"/None]
        """
        num_clients = len(gradients)
        
        if num_clients < 2:
            return (
                {cid: Layer2Result.ACCEPTED.value for cid in client_ids},
                {cid: SuspicionLevel.CLEAN.value for cid in client_ids}
            )
        
        # =========================================================
        # STEP 1: TÃ­nh toÃ¡n metrics (cho táº¥t cáº£ clients)
        # =========================================================
        # Truyá»n external_reference xuá»‘ng Ä‘á»ƒ tÃ­nh khoáº£ng cÃ¡ch chuáº©n xÃ¡c
        distances, cosines, median_grad = self._compute_metrics(gradients, reference_vector=external_reference)
        
        # TÃ­nh ngÆ°á»¡ng distance Ä‘á»™ng (Adaptive Threshold)
        median_distance = np.median(distances)
        distance_threshold = self.distance_multiplier * median_distance
        
        # =========================================================
        # STEP 2: Ãp dá»¥ng ma tráº­n quyáº¿t Ä‘á»‹nh
        # =========================================================
        final_status = {}
        suspicion_levels = {}
        
        # Stats for debugging
        stats = {
            "median_distance": float(median_distance),
            "distance_threshold": float(distance_threshold),
            "cosine_threshold": self.cosine_threshold,
            "decisions": []
        }
        
        for i, cid in enumerate(client_ids):
            layer1_status = layer1_results.get(cid, "ACCEPTED")
            dist = distances[i]
            cos = cosines[i]
            
            # Logic check vi pháº¡m
            fail_distance = dist > distance_threshold
            fail_cosine = cos <= self.cosine_threshold
            
            # Ãp dá»¥ng ma tráº­n quyáº¿t Ä‘á»‹nh
            result, suspicion = self._apply_decision_matrix(
                layer1_status, fail_cosine, fail_distance
            )
            
            final_status[cid] = result.value
            suspicion_levels[cid] = suspicion.value if suspicion else None
            
            stats["decisions"].append({
                "client_id": cid,
                "layer1": layer1_status,
                "distance": float(dist),
                "cosine": float(cos),
                "fail_distance": fail_distance,
                "fail_cosine": fail_cosine,
                "final": result.value,
                "suspicion": suspicion.value if suspicion else None
            })
        
        self.last_stats = stats
        
        # Log results
        self._log_results(
            client_ids, final_status, suspicion_levels,
            layer1_results, is_malicious_ground_truth, current_round
        )
        
        return final_status, suspicion_levels

    def _compute_metrics(
        self, 
        gradients: List[np.ndarray],
        reference_vector: Optional[np.ndarray] = None
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        TÃ­nh Euclidean distance vÃ  Cosine similarity.
        Há»— trá»£ External Reference (Momentum).
        """
        # Stack gradients thÃ nh ma tráº­n (N x D)
        # Vá»›i Full Model: D ~ 3.2 triá»‡u.
        # LÆ°u Ã½: CÃ³ thá»ƒ tá»‘n RAM, nhÆ°ng numpy xá»­ lÃ½ tá»‘t náº¿u RAM > 4GB.
        grad_matrix = np.vstack([g.flatten() for g in gradients])
        
        # XÃ¡c Ä‘á»‹nh Vector Tham Chiáº¿u (Reference Vector)
        if reference_vector is not None:
            # Æ¯u tiÃªn 1: DÃ¹ng Lá»‹ch sá»­ tá»« Server (Chá»‘ng >50% Attack)
            median_grad = reference_vector
        else:
            # Æ¯u tiÃªn 2: DÃ¹ng Median cá»§a vÃ²ng hiá»‡n táº¡i (Fallback)
            median_grad = np.median(grad_matrix, axis=0)
        
        # Euclidean distances: ||gi - gref||
        distances = np.array([
            np.linalg.norm(g - median_grad) for g in grad_matrix
        ])
        
        # Cosine similarities: dot(gi, gref) / (|gi|*|gref|)
        median_norm = np.linalg.norm(median_grad)
        cosines = []
        for g in grad_matrix:
            g_norm = np.linalg.norm(g)
            if g_norm < 1e-9 or median_norm < 1e-9:
                cosines.append(0.0)
            else:
                cos = np.dot(g, median_grad) / (g_norm * median_norm)
                cosines.append(float(np.clip(cos, -1.0, 1.0)))
        
        return distances, np.array(cosines), median_grad

    def _apply_decision_matrix(
        self,
        layer1_status: str,
        fail_cosine: bool,
        fail_distance: bool
    ) -> Tuple[Layer2Result, Optional[SuspicionLevel]]:
        """
        Ãp dá»¥ng ma tráº­n quyáº¿t Ä‘á»‹nh
        """
        # REJECTED tá»« Layer 1 â†’ Giá»¯ nguyÃªn
        if layer1_status == "REJECTED":
            return Layer2Result.REJECTED, None
        
        # Kiá»ƒm tra Cosine (quan trá»ng nháº¥t - hÆ°á»›ng gradient)
        if fail_cosine:
            # HÆ°á»›ng sai â†’ REJECTED
            return Layer2Result.REJECTED, None
        
        # Cosine OK, xÃ©t theo Layer 1 status
        if layer1_status == "FLAGGED":
            if self.enable_rescue:
                return Layer2Result.ACCEPTED, SuspicionLevel.SUSPICIOUS
            else:
                return Layer2Result.REJECTED, None
        
        # L1 ACCEPTED + Cosine OK
        if fail_distance:
            # Distance lá»›n nhÆ°ng hÆ°á»›ng Ä‘Ãºng â†’ nghi ngá»
            return Layer2Result.ACCEPTED, SuspicionLevel.SUSPICIOUS
        
        # L1 ACCEPTED + Cosine OK + Distance OK â†’ HoÃ n toÃ n sáº¡ch
        return Layer2Result.ACCEPTED, SuspicionLevel.CLEAN

    def _log_results(
        self,
        client_ids: List[int],
        final_status: Dict[int, str],
        suspicion_levels: Dict[int, Optional[str]],
        layer1_results: Dict[int, str],
        ground_truth: Optional[List[bool]],
        current_round: int
    ):
        """Log káº¿t quáº£ Layer 2."""
        rejected_count = sum(1 for s in final_status.values() if s == "REJECTED")
        accepted_count = sum(1 for s in final_status.values() if s == "ACCEPTED")
        
        clean_count = sum(1 for s in suspicion_levels.values() if s == "clean")
        suspicious_count = sum(1 for s in suspicion_levels.values() if s == "suspicious")
        
        rescued = sum(
            1 for cid in client_ids 
            if layer1_results.get(cid) == "FLAGGED" and final_status.get(cid) == "ACCEPTED"
        )
        
        confirmed = sum(
            1 for cid in client_ids
            if layer1_results.get(cid) == "FLAGGED" and final_status.get(cid) == "REJECTED"
        )
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š Layer 2 Results - Round {current_round}")
        print(f"{'='*60}")
        print(f"   Final Status:")
        print(f"      REJECTED: {rejected_count}")
        print(f"      ACCEPTED: {accepted_count}")
        print(f"   Suspicion Levels (ACCEPTED only):")
        print(f"      Clean: {clean_count}")
        print(f"      Suspicious: {suspicious_count}")
        print(f"   Layer 1 â†’ Layer 2 Changes:")
        print(f"      Rescued (FLAGGEDâ†’ACCEPTED): {rescued}")
        print(f"      Confirmed (FLAGGEDâ†’REJECTED): {confirmed}")
        
        if ground_truth:
            actual_malicious = [i for i, m in enumerate(ground_truth) if m]
            detected = [i for i, cid in enumerate(client_ids) 
                       if final_status.get(cid) == "REJECTED"]
            
            tp = len(set(actual_malicious) & set(detected))
            fp = len(set(detected) - set(actual_malicious))
            
            detection_rate = tp / len(actual_malicious) if actual_malicious else 0
            benign_count = len(ground_truth) - len(actual_malicious)
            fpr = fp / benign_count if benign_count > 0 else 0
            
            print(f"\n   ğŸ“ˆ Final Metrics (after Layer 2):")
            print(f"      Detection Rate: {detection_rate:.1%} ({tp}/{len(actual_malicious)})")
            print(f"      False Positive Rate: {fpr:.1%} ({fp}/{benign_count})")
        
        print(f"{'='*60}\n")

    def get_stats(self) -> Dict:
        """Get last detection stats."""
        return self.last_stats