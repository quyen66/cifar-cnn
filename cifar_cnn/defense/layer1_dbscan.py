"""
Layer 1: Enhanced DBSCAN Detection (V2 - main.pdf)
====================================================
Giai ƒëo·∫°n 2: Hai l·ªõp ph√°t hi·ªán tu·∫ßn t·ª±

Pipeline:
1. Magnitude Filter (kh√¥ng gian g·ªëc) ‚Üí 3 tr·∫°ng th√°i
   - REJECTED: ||gi|| > Median + 15√óMAD (lo·∫°i ngay, b·ªè qua DBSCAN)
   - FLAGGED: ||gi|| > Median + 4√óMAD
   - ACCEPTED: ||gi|| ‚â§ Median + 4√óMAD

2. DBSCAN Clustering (CH·ªà cho clients KH√îNG b·ªã REJECTED)
   - PCA gi·∫£m chi·ªÅu: dpca = min(20, floor(0.5√ón_remaining))
   - DBSCAN: Œµ = 0.5√ómedian_dist, minPts = 3
   - Outliers (label=-1) ‚Üí FLAGGED

Output: Dict[client_id, status] v·ªõi status ‚àà {"REJECTED", "FLAGGED", "ACCEPTED"}

L∆ØU √ù: Module n√†y CH·ªà CH·∫†Y SAU WARMUP (v√≤ng 11+)
"""

import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import euclidean_distances
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum


class Layer1Status(Enum):
    """Tr·∫°ng th√°i c·ªßa client sau Layer 1."""
    REJECTED = "REJECTED"   # Lo·∫°i ngay, kh√¥ng qua Layer 2
    FLAGGED = "FLAGGED"     # Nghi ng·ªù, c·∫ßn Layer 2 ki·ªÉm tra
    ACCEPTED = "ACCEPTED"   # T·∫°m ch·∫•p nh·∫≠n


@dataclass
class Layer1Result:
    """K·∫øt qu·∫£ chi ti·∫øt c·ªßa Layer 1."""
    status: Dict[int, str]              # client_id -> status string
    magnitude_stats: Dict                # Th·ªëng k√™ magnitude filter
    dbscan_stats: Dict                   # Th·ªëng k√™ DBSCAN
    rejected_ids: List[int]             # IDs b·ªã REJECTED
    flagged_ids: List[int]              # IDs b·ªã FLAGGED
    accepted_ids: List[int]             # IDs ƒë∆∞·ª£c ACCEPTED


class Layer1Detector:
    """
    Layer 1 Detector v·ªõi 3 tr·∫°ng th√°i (V2 - main.pdf).
    
    ƒê·∫∑c ƒëi·ªÉm:
    - Magnitude Filter b·∫£o v·ªá PCA kh·ªèi outliers c·ª±c ƒëoan
    - DBSCAN ch·ªâ ch·∫°y tr√™n clients kh√¥ng b·ªã REJECTED (ti·∫øt ki·ªám t√†i nguy√™n)
    - PCA dims ƒë·ªông theo s·ªë clients c√≤n l·∫°i
    """
    
    def __init__(
        self,
        pca_dims: int = 20,
        dbscan_min_samples: int = 3,
        dbscan_eps_multiplier: float = 0.5,
        mad_k_reject: float = 15.0,
        mad_k_flag: float = 4.0,
        voting_threshold: int = 2
    ):
        """
        Initialize Layer 1 Detector.
        
        Args:
            pca_dims: Target max PCA dimensions
            dbscan_min_samples: minPts for DBSCAN (default=3)
            dbscan_eps_multiplier: eps = mult √ó median_dist (default=0.5)
            mad_k_reject: k for REJECTED threshold (default=15)
            mad_k_flag: k for FLAGGED threshold (default=4)
            voting_threshold: Unused, kept for compatibility
        """
        self.target_pca_dims = pca_dims
        self.min_samples = dbscan_min_samples
        self.eps_multiplier = dbscan_eps_multiplier
        self.mad_k_reject = mad_k_reject
        self.mad_k_flag = mad_k_flag
        
        # Stats
        self.last_result: Optional[Layer1Result] = None
        
        print(f"‚úÖ Layer1Detector V2 initialized:")
        print(f"   Magnitude: k_reject={mad_k_reject}, k_flag={mad_k_flag}")
        print(f"   DBSCAN: minPts={dbscan_min_samples}, eps_mult={dbscan_eps_multiplier}")
        print(f"   PCA dims (target): {pca_dims}")

    def detect(
        self,
        gradients: List[np.ndarray],
        client_ids: List[int],
        current_round: int = 0,
        is_malicious_ground_truth: Optional[List[bool]] = None
    ) -> Dict[int, str]:
        """
        Ph√°t hi·ªán v√† ph√¢n lo·∫°i clients th√†nh 3 tr·∫°ng th√°i.
        
        Pipeline theo main.pdf:
        1. Magnitude Filter ‚Üí REJECTED/FLAGGED/ACCEPTED
        2. DBSCAN (ch·ªâ cho non-REJECTED) ‚Üí c√≥ th·ªÉ n√¢ng l√™n FLAGGED
        
        Args:
            gradients: List gradient arrays t·ª´ clients
            client_ids: List client IDs
            current_round: Round hi·ªán t·∫°i (for logging)
            is_malicious_ground_truth: Ground truth (optional, for metrics)
            
        Returns:
            Dict[client_id, status] v·ªõi status ‚àà {"REJECTED", "FLAGGED", "ACCEPTED"}
        """
        num_clients = len(gradients)
        
        # Edge case
        if num_clients < 2:
            result = {cid: Layer1Status.ACCEPTED.value for cid in client_ids}
            self.last_result = Layer1Result(
                status=result,
                magnitude_stats={},
                dbscan_stats={},
                rejected_ids=[],
                flagged_ids=[],
                accepted_ids=list(client_ids)
            )
            return result
        
        # =========================================================
        # STEP 1: Magnitude Filter (3 ng∆∞·ª°ng)
        # =========================================================
        mag_status, mag_stats = self._magnitude_filter(gradients, client_ids)
        
        # Ph√¢n lo·∫°i theo magnitude
        rejected_indices = [i for i, s in enumerate(mag_status) if s == Layer1Status.REJECTED]
        non_rejected_indices = [i for i, s in enumerate(mag_status) if s != Layer1Status.REJECTED]
        
        # =========================================================
        # STEP 2: DBSCAN (CH·ªà cho clients KH√îNG b·ªã REJECTED)
        # =========================================================
        # Theo PDF: "Ki·ªÉm tra m·∫≠t ƒë·ªô DBSCAN: √Åp d·ª•ng cho c√°c m√°y kh√°ch 
        # ch∆∞a b·ªã g·∫Øn c·ªù REJECTED"
        
        dbscan_stats = {"skipped": True, "reason": "No non-rejected clients"}
        
        if len(non_rejected_indices) >= 2:
            # L·∫•y gradients c·ªßa clients kh√¥ng b·ªã REJECTED
            non_rejected_grads = [gradients[i] for i in non_rejected_indices]
            non_rejected_cids = [client_ids[i] for i in non_rejected_indices]
            
            # Ch·∫°y DBSCAN
            dbscan_flags, dbscan_stats = self._dbscan_filter(
                non_rejected_grads, 
                non_rejected_cids,
                len(non_rejected_indices)
            )
            
            # C·∫≠p nh·∫≠t status: N·∫øu DBSCAN flag ‚Üí FLAGGED
            for idx, orig_idx in enumerate(non_rejected_indices):
                if dbscan_flags[idx]:
                    # DBSCAN th·∫•y outlier ‚Üí n√¢ng l√™n FLAGGED
                    mag_status[orig_idx] = Layer1Status.FLAGGED
        
        # =========================================================
        # STEP 3: Build final result
        # =========================================================
        final_status = {
            client_ids[i]: mag_status[i].value 
            for i in range(num_clients)
        }
        
        # Categorize
        rejected_ids = [client_ids[i] for i in range(num_clients) 
                       if mag_status[i] == Layer1Status.REJECTED]
        flagged_ids = [client_ids[i] for i in range(num_clients) 
                      if mag_status[i] == Layer1Status.FLAGGED]
        accepted_ids = [client_ids[i] for i in range(num_clients) 
                       if mag_status[i] == Layer1Status.ACCEPTED]
        
        # Store result
        self.last_result = Layer1Result(
            status=final_status,
            magnitude_stats=mag_stats,
            dbscan_stats=dbscan_stats,
            rejected_ids=rejected_ids,
            flagged_ids=flagged_ids,
            accepted_ids=accepted_ids
        )
        
        # Log
        self._log_results(current_round, is_malicious_ground_truth, client_ids, mag_status)
        
        return final_status

    def _magnitude_filter(
        self, 
        gradients: List[np.ndarray],
        client_ids: List[int]
    ) -> Tuple[List[Layer1Status], Dict]:
        """
        Magnitude Filter v·ªõi 3 ng∆∞·ª°ng.
        
        Theo PDF:
        - œÑ(k) = Median(||gj||) + k √ó MAD
        - REJECTED: ||gi|| > œÑ(15)
        - FLAGGED: ||gi|| > œÑ(4)
        - ACCEPTED: ||gi|| ‚â§ œÑ(4)
        
        Returns:
            status: List[Layer1Status]
            stats: Dict v·ªõi th√¥ng tin debug
        """
        # T√≠nh norms
        norms = np.array([np.linalg.norm(g) for g in gradients])
        
        # T√≠nh Median v√† MAD
        median_norm = np.median(norms)
        mad = np.median(np.abs(norms - median_norm))
        
        # Tr√°nh MAD = 0 (t·∫•t c·∫£ gradient gi·ªëng nhau)
        effective_mad = mad if mad > 1e-9 else 1.0
        
        # T√≠nh ng∆∞·ª°ng
        threshold_reject = median_norm + self.mad_k_reject * effective_mad  # k=15
        threshold_flag = median_norm + self.mad_k_flag * effective_mad      # k=4
        
        # Ph√¢n lo·∫°i
        status = []
        for i, norm in enumerate(norms):
            if norm > threshold_reject:
                status.append(Layer1Status.REJECTED)
            elif norm > threshold_flag:
                status.append(Layer1Status.FLAGGED)
            else:
                status.append(Layer1Status.ACCEPTED)
        
        # Stats
        stats = {
            "median_norm": float(median_norm),
            "mad": float(mad),
            "effective_mad": float(effective_mad),
            "threshold_reject": float(threshold_reject),
            "threshold_flag": float(threshold_flag),
            "k_reject": self.mad_k_reject,
            "k_flag": self.mad_k_flag,
            "counts": {
                "rejected": sum(1 for s in status if s == Layer1Status.REJECTED),
                "flagged": sum(1 for s in status if s == Layer1Status.FLAGGED),
                "accepted": sum(1 for s in status if s == Layer1Status.ACCEPTED)
            },
            "norms": {client_ids[i]: float(norms[i]) for i in range(len(norms))}
        }
        
        return status, stats

    def _dbscan_filter(
        self, 
        gradients: List[np.ndarray],
        client_ids: List[int],
        num_clients: int
    ) -> Tuple[List[bool], Dict]:
        """
        DBSCAN clustering tr√™n PCA space.
        
        Theo PDF:
        - dpca = min(20, floor(0.5√ón))
        - Œµ = 0.5 √ó median_dist
        - minPts = 3
        - Outliers (label=-1) ‚Üí FLAGGED
        
        Returns:
            flags: List[bool] - True n·∫øu l√† outlier (c·∫ßn FLAGGED)
            stats: Dict v·ªõi th√¥ng tin debug
        """
        # Dynamic PCA dims theo PDF
        density_dims = max(2, int(num_clients * 0.5))
        actual_pca_dims = min(self.target_pca_dims, density_dims, num_clients)
        
        flags = [False] * num_clients
        stats = {
            "skipped": False,
            "num_clients_analyzed": num_clients,
            "pca_dims_target": self.target_pca_dims,
            "pca_dims_actual": actual_pca_dims,
            "eps": 0,
            "min_samples": self.min_samples,
            "outlier_count": 0,
            "cluster_count": 0
        }
        
        if actual_pca_dims < 2 or num_clients < self.min_samples:
            stats["skipped"] = True
            stats["reason"] = f"Not enough clients ({num_clients}) or dims ({actual_pca_dims})"
            return flags, stats
        
        try:
            # Stack gradients
            grad_matrix = np.vstack([g.flatten() for g in gradients])
            
            # PCA gi·∫£m chi·ªÅu (Randomized cho hi·ªáu qu·∫£)
            pca = PCA(n_components=actual_pca_dims, svd_solver='randomized', random_state=42)
            reduced = pca.fit_transform(grad_matrix)
            
            # T√≠nh eps ƒë·ªông: Œµ = 0.5 √ó median_dist
            dists = euclidean_distances(reduced)
            # L·∫•y upper triangle (kh√¥ng k·ªÉ diagonal)
            upper_indices = np.triu_indices(num_clients, k=1)
            upper_dists = dists[upper_indices]
            
            if len(upper_dists) > 0:
                median_dist = np.median(upper_dists)
            else:
                median_dist = 1.0
                
            eps = max(self.eps_multiplier * median_dist, 1e-6)
            
            # DBSCAN
            clustering = DBSCAN(
                eps=eps, 
                min_samples=self.min_samples, 
                metric='euclidean'
            )
            labels = clustering.fit_predict(reduced)
            
            # Outliers (label=-1) ‚Üí c·∫ßn FLAGGED
            flags = [label == -1 for label in labels]
            
            # Count clusters (kh√¥ng k·ªÉ noise)
            unique_labels = set(labels)
            cluster_count = len([l for l in unique_labels if l != -1])
            
            # Update stats
            stats["eps"] = float(eps)
            stats["median_dist"] = float(median_dist)
            stats["outlier_count"] = sum(flags)
            stats["cluster_count"] = cluster_count
            stats["labels"] = {client_ids[i]: int(labels[i]) for i in range(len(labels))}
            stats["explained_variance_ratio"] = pca.explained_variance_ratio_.tolist()
            
        except Exception as e:
            stats["skipped"] = True
            stats["reason"] = f"Exception: {str(e)}"
            print(f"‚ö†Ô∏è DBSCAN failed: {e}")
            
        return flags, stats

    def _log_results(
        self,
        current_round: int,
        ground_truth: Optional[List[bool]],
        client_ids: List[int],
        status: List[Layer1Status]
    ):
        """Log k·∫øt qu·∫£ detection."""
        if self.last_result is None:
            return
            
        r = self.last_result
        mag = r.magnitude_stats
        db = r.dbscan_stats
        
        print(f"\n{'='*65}")
        print(f"üìä LAYER 1 RESULTS - Round {current_round}")
        print(f"{'='*65}")
        
        # Magnitude stats
        print(f"\nüîç Magnitude Filter:")
        print(f"   Median norm: {mag.get('median_norm', 0):.4f}")
        print(f"   MAD: {mag.get('mad', 0):.4f}")
        print(f"   Threshold REJECT (k={mag.get('k_reject')}): {mag.get('threshold_reject', 0):.4f}")
        print(f"   Threshold FLAG (k={mag.get('k_flag')}): {mag.get('threshold_flag', 0):.4f}")
        
        mag_counts = mag.get('counts', {})
        print(f"   Results: REJECTED={mag_counts.get('rejected', 0)}, "
              f"FLAGGED={mag_counts.get('flagged', 0)}, "
              f"ACCEPTED={mag_counts.get('accepted', 0)}")
        
        # DBSCAN stats
        print(f"\nüîç DBSCAN Clustering:")
        if db.get('skipped'):
            print(f"   ‚ö†Ô∏è Skipped: {db.get('reason', 'Unknown')}")
        else:
            print(f"   Clients analyzed: {db.get('num_clients_analyzed', 0)}")
            print(f"   PCA dims: {db.get('pca_dims_actual', 0)} (target={db.get('pca_dims_target', 0)})")
            print(f"   eps: {db.get('eps', 0):.4f} (median_dist={db.get('median_dist', 0):.4f})")
            print(f"   Clusters found: {db.get('cluster_count', 0)}")
            print(f"   Outliers (‚ÜíFLAGGED): {db.get('outlier_count', 0)}")
        
        # Final counts
        print(f"\nüìã Final Status:")
        print(f"   REJECTED: {len(r.rejected_ids)} {r.rejected_ids if len(r.rejected_ids) <= 10 else '...'}")
        print(f"   FLAGGED:  {len(r.flagged_ids)} {r.flagged_ids if len(r.flagged_ids) <= 10 else '...'}")
        print(f"   ACCEPTED: {len(r.accepted_ids)} {r.accepted_ids if len(r.accepted_ids) <= 10 else '...'}")
        
        # Metrics vs ground truth
        if ground_truth:
            num_clients = len(ground_truth)
            actual_malicious_idx = [i for i, m in enumerate(ground_truth) if m]
            detected_idx = [i for i, s in enumerate(status) if s != Layer1Status.ACCEPTED]
            
            tp = len(set(actual_malicious_idx) & set(detected_idx))
            fp = len(set(detected_idx) - set(actual_malicious_idx))
            fn = len(set(actual_malicious_idx) - set(detected_idx))
            tn = num_clients - tp - fp - fn
            
            detection_rate = tp / len(actual_malicious_idx) if actual_malicious_idx else 0
            benign_count = num_clients - len(actual_malicious_idx)
            fpr = fp / benign_count if benign_count > 0 else 0
            
            print(f"\nüìà Metrics (vs ground truth):")
            print(f"   True Positives: {tp}/{len(actual_malicious_idx)} malicious detected")
            print(f"   False Positives: {fp}/{benign_count} benign flagged")
            print(f"   Detection Rate: {detection_rate:.1%}")
            print(f"   False Positive Rate: {fpr:.1%}")
        
        print(f"{'='*65}\n")

    def get_result(self) -> Optional[Layer1Result]:
        """Get last detection result."""
        return self.last_result
    
    def get_stats(self) -> Dict:
        """Get stats as dict (for compatibility)."""
        if self.last_result is None:
            return {}
        return {
            "magnitude": self.last_result.magnitude_stats,
            "dbscan": self.last_result.dbscan_stats,
            "rejected_count": len(self.last_result.rejected_ids),
            "flagged_count": len(self.last_result.flagged_ids),
            "accepted_count": len(self.last_result.accepted_ids)
        }